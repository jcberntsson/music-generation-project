{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combine_piano_roll(midi_data, fs):\n",
    "    mat = None\n",
    "    for inst in midi_data.instruments:\n",
    "        print(inst)\n",
    "        if (inst.is_drum == False):\n",
    "            if (mat is None):\n",
    "                mat = inst.get_piano_roll(fs=fs)\n",
    "            else:\n",
    "                mat += inst.get_piano_roll(fs=fs)\n",
    "\n",
    "    mat[mat > 0] = 1\n",
    "    return mat\n",
    "\n",
    "# Split into 10 seconds chunks\n",
    "def split_sample(sample, length, sliding_factor):\n",
    "    (pitch_level, time_steps) = sample.shape\n",
    "    n_samples = int(time_steps / length * sliding_factor)\n",
    "    print(n_samples)\n",
    "    samples = np.zeros((n_samples, pitch_level, length))\n",
    "    for i in range(0, n_samples):\n",
    "        start = int(i * length / sliding_factor)\n",
    "        end = start + length\n",
    "        samples[i] = sample[:,start:end]\n",
    "    return samples\n",
    "\n",
    "def split_sample(sample, length, n_samples):\n",
    "    (pitch_level, time_steps) = sample.shape\n",
    "    samples = np.zeros((n_samples, pitch_level, length))\n",
    "    max_start = time_steps - length\n",
    "    for i in range(0, n_samples):\n",
    "        start = int(i * max_start / n_samples)\n",
    "        end = start + length\n",
    "        samples[i] = sample[:,start:end]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instrument(program=0, is_drum=False, name=\"Right Hand\")\n",
      "Instrument(program=0, is_drum=False, name=\"Left Hand\")\n",
      "(128, 3888)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "midi_data = pretty_midi.PrettyMIDI('data/Zelda_Overworld.mid')\n",
    "\n",
    "mat = generate_combine_piano_roll(midi_data, FS)\n",
    "print(mat.shape)\n",
    "cax = plt.matshow(mat, aspect=\"auto\")\n",
    "plt.colorbar(cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 51200)\n"
     ]
    }
   ],
   "source": [
    "length = 512\n",
    "samples = split_sample(mat, 512, 100)\n",
    "new_track = np.concatenate(samples, axis=1)\n",
    "#print(new_track.shape)\n",
    "#pm = piano_roll_to_pretty_midi(new_track * 75, fs=FS, program=0)\n",
    "#pm.write(\"pianoroll.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piano_roll_to_pretty_midi(piano_roll, fs=100, program=0):\n",
    "    '''Convert a Piano Roll array into a PrettyMidi object\n",
    "     with a single instrument.\n",
    "    Parameters\n",
    "    ----------\n",
    "    piano_roll : np.ndarray, shape=(128,frames), dtype=int\n",
    "        Piano roll of one instrument\n",
    "    fs : int\n",
    "        Sampling frequency of the columns, i.e. each column is spaced apart\n",
    "        by ``1./fs`` seconds.\n",
    "    program : int\n",
    "        The program number of the instrument.\n",
    "    Returns\n",
    "    -------\n",
    "    midi_object : pretty_midi.PrettyMIDI\n",
    "        A pretty_midi.PrettyMIDI class instance describing\n",
    "        the piano roll.\n",
    "    '''\n",
    "    notes, frames = piano_roll.shape\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=program)\n",
    "\n",
    "    # pad 1 column of zeros so we can acknowledge inital and ending events\n",
    "    piano_roll = np.pad(piano_roll, [(0, 0), (1, 1)], 'constant')\n",
    "\n",
    "    # use changes in velocities to find note on / note off events\n",
    "    velocity_changes = np.nonzero(np.diff(piano_roll).T)\n",
    "\n",
    "    # keep track on velocities and note on times\n",
    "    prev_velocities = np.zeros(notes, dtype=int)\n",
    "    note_on_time = np.zeros(notes)\n",
    "\n",
    "    for time, note in zip(*velocity_changes):\n",
    "        # use time + 1 because of padding above\n",
    "        velocity = piano_roll[note, time + 1]\n",
    "        time = time / fs\n",
    "        if velocity > 0:\n",
    "            if prev_velocities[note] == 0:\n",
    "                note_on_time[note] = time\n",
    "                prev_velocities[note] = velocity\n",
    "        else:\n",
    "            pm_note = pretty_midi.Note(\n",
    "                velocity=prev_velocities[note],\n",
    "                pitch=note,\n",
    "                start=note_on_time[note],\n",
    "                end=time)\n",
    "            instrument.notes.append(pm_note)\n",
    "            prev_velocities[note] = 0\n",
    "    pm.instruments.append(instrument)\n",
    "    return pm\n",
    "pm = piano_roll_to_pretty_midi(mat * 75, fs=FS, program=0)\n",
    "pm.write(\"pianoroll.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.merge import _Merge\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from functools import partial\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large amount of credit goes to:\n",
    "# https://github.com/keras-team/keras-contrib/blob/master/examples/improved_wgan.py\n",
    "# which I've used as a reference for this implementation\n",
    "\n",
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((self.batch_size, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "\n",
    "class WGANGP():\n",
    "    def __init__(self, img_rows, img_cols, channels, batch_size):\n",
    "        # Input shape\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channels = channels\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "        # Build the generator and critic\n",
    "        self.generator = self.build_generator()\n",
    "        self.critic = self.build_critic()\n",
    "\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #       for the Critic\n",
    "        #-------------------------------\n",
    "\n",
    "        # Freeze generator's layers while training critic\n",
    "        self.generator.trainable = False\n",
    "\n",
    "        # Image input (real sample)\n",
    "        real_img = Input(shape=self.img_shape)\n",
    "\n",
    "        # Noise input\n",
    "        z_disc = Input(shape=(self.latent_dim,))\n",
    "        # Generate image based of noise (fake sample)\n",
    "        fake_img = self.generator(z_disc)\n",
    "\n",
    "        # Discriminator determines validity of the real and fake images\n",
    "        fake = self.critic(fake_img)\n",
    "        valid = self.critic(real_img)\n",
    "\n",
    "        # Construct weighted average between real and fake images\n",
    "        interpolated_img = RandomWeightedAverage(self.batch_size)([real_img, fake_img])\n",
    "        # Determine validity of weighted sample\n",
    "        validity_interpolated = self.critic(interpolated_img)\n",
    "\n",
    "        # Use Python partial to provide loss function with additional\n",
    "        # 'averaged_samples' argument\n",
    "        partial_gp_loss = partial(self.gradient_penalty_loss,\n",
    "                          averaged_samples=interpolated_img)\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
    "\n",
    "        self.critic_model = Model(inputs=[real_img, z_disc],\n",
    "                            outputs=[valid, fake, validity_interpolated])\n",
    "        self.critic_model.compile(loss=[self.wasserstein_loss,\n",
    "                                              self.wasserstein_loss,\n",
    "                                              partial_gp_loss],\n",
    "                                        optimizer=optimizer,\n",
    "                                        loss_weights=[1, 1, 10])\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #         for Generator\n",
    "        #-------------------------------\n",
    "\n",
    "        # For the generator we freeze the critic's layers\n",
    "        self.critic.trainable = False\n",
    "        self.generator.trainable = True\n",
    "\n",
    "        # Sampled noise for input to generator\n",
    "        z_gen = Input(shape=(100,))\n",
    "        # Generate images based of noise\n",
    "        img = self.generator(z_gen)\n",
    "        # Discriminator determines validity\n",
    "        valid = self.critic(img)\n",
    "        # Defines generator model\n",
    "        self.generator_model = Model(z_gen, valid)\n",
    "        self.generator_model.compile(loss=self.wasserstein_loss, optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
    "        \"\"\"\n",
    "        Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "        \"\"\"\n",
    "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "        # compute the euclidean norm by squaring ...\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        #   ... summing over the rows ...\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                                  axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        #   ... and sqrt\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "        # return the mean as loss over all the batch samples\n",
    "        return K.mean(gradient_penalty)\n",
    "\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    def build_generator(self):\n",
    "        return build_generator(self.latent_dim, self.channels)\n",
    "\n",
    "    def build_critic(self):\n",
    "        return build_discriminator(self.img_shape)\n",
    "\n",
    "    def train(self, X_train, epochs, sample_interval=50):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((self.batch_size, 1))\n",
    "        fake =  np.ones((self.batch_size, 1))\n",
    "        dummy = np.zeros((self.batch_size, 1)) # Dummy gt for gradient penalty\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for _ in range(self.n_critic):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Select a random batch of images\n",
    "                idx = np.random.randint(0, X_train.shape[0], self.batch_size)\n",
    "                imgs = X_train[idx]\n",
    "                # Sample generator input\n",
    "                noise = np.random.normal(0, 1, (self.batch_size, self.latent_dim))\n",
    "                # Train the critic\n",
    "                d_loss = self.critic_model.train_on_batch([imgs, noise],\n",
    "                                                                [valid, fake, dummy])\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            g_loss = self.generator_model.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss[0], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        n_images = 1\n",
    "        noise = np.random.normal(0, 1, (n_images, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        print(\"Generated shape\", gen_imgs.shape)\n",
    "        img = gen_imgs.reshape(128, 512)\n",
    "        \n",
    "        img[img < 0.1] = 0 # Remove some notes\n",
    "        \n",
    "        pm = piano_roll_to_pretty_midi(img * 75, fs=FS, program=0)\n",
    "        pm.write(\"output/pianoroll-%d.mid\" % epoch)\n",
    "        \n",
    "        cax = plt.matshow(img, aspect=\"auto\")\n",
    "        plt.colorbar(cax)\n",
    "        plt.savefig(\"output/pianoroll-%d.png\" % epoch)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    def __init__(self, img_rows, img_cols, channels):\n",
    "        # Input shape\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channels = channels\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "        return build_generator(self.latent_dim, self.channels)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        return build_discriminator(self.img_shape)\n",
    "\n",
    "    def train(self, X_train, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        #X_train = train_data / 127.5 - 1.\n",
    "        #X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select random batch\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        n_images = 1\n",
    "        noise = np.random.normal(0, 1, (n_images, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        print(\"Generated shape\", gen_imgs.shape)\n",
    "        img = gen_imgs.reshape(128, 512)\n",
    "        \n",
    "        img[img < 0.1] = 0 # Remove some notes\n",
    "        \n",
    "        pm = piano_roll_to_pretty_midi(img * 75, fs=FS, program=0)\n",
    "        pm.write(\"output/pianoroll-%d.mid\" % epoch)\n",
    "        \n",
    "        cax = plt.matshow(img, aspect=\"auto\")\n",
    "        plt.colorbar(cax)\n",
    "        plt.savefig(\"output/pianoroll-%d.png\" % epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim, channels):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128 * 2 * 8, activation=\"relu\", input_dim=latent_dim))\n",
    "    model.add(Reshape((2, 8, 128)))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.add(UpSampling2D((2,2)))\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.add(UpSampling2D((2,2)))\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.add(UpSampling2D((2,2)))\n",
    "    model.add(Conv2D(32, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.add(UpSampling2D((2,2)))\n",
    "    model.add(Conv2D(32, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.add(UpSampling2D((2,2)))\n",
    "    model.add(Conv2D(32, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "    print(\"Generator model\")\n",
    "    model.summary()\n",
    "\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    img = model(noise)\n",
    "\n",
    "    return Model(noise, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(4,89), strides=2, input_shape=img_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=(4,1), strides=2, padding=\"same\"))\n",
    "    #model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=(4,1), strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    #model.add(Conv2D(256, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    #model.add(BatchNormalization(momentum=0.8))\n",
    "    #model.add(LeakyReLU(alpha=0.2))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    print(\"Discriminator model\")\n",
    "    model.summary()\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n_samples, pitch_level, time_span) = samples.shape\n",
    "train_data = samples.reshape(n_samples, pitch_level, time_span, 1)\n",
    "\n",
    "#dcgan = DCGAN(pitch_level,time_span,1)\n",
    "#dcgan.train(train_data, epochs=1000, batch_size=64, save_interval=50)\n",
    "\n",
    "wgan = WGANGP(pitch_level,time_span,1, batch_size=64)\n",
    "wgan.train(train_data, epochs=30000, sample_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
