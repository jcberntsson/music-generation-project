{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combine_piano_roll(midi_data, fs):\n",
    "    mat = None\n",
    "    for inst in midi_data.instruments:\n",
    "        print(inst)\n",
    "        if (inst.is_drum == False):\n",
    "            if (mat is None):\n",
    "                mat = inst.get_piano_roll(fs=fs)\n",
    "            else:\n",
    "                mat += inst.get_piano_roll(fs=fs)\n",
    "\n",
    "    mat[mat > 0] = 1\n",
    "    return mat\n",
    "\n",
    "# Split into 10 seconds chunks\n",
    "def split_sample(sample, length, sliding_factor):\n",
    "    (pitch_level, time_steps) = sample.shape\n",
    "    n_samples = int(time_steps / length * sliding_factor)\n",
    "    print(n_samples)\n",
    "    samples = np.zeros((n_samples, pitch_level, length))\n",
    "    for i in range(0, n_samples):\n",
    "        start = int(i * length / sliding_factor)\n",
    "        end = start + length\n",
    "        samples[i] = sample[:,start:end]\n",
    "    return samples\n",
    "\n",
    "def split_sample(sample, length, n_samples):\n",
    "    (pitch_level, time_steps) = sample.shape\n",
    "    samples = np.zeros((n_samples, pitch_level, length))\n",
    "    max_start = time_steps - length\n",
    "    for i in range(0, n_samples):\n",
    "        start = int(i * max_start / n_samples)\n",
    "        end = start + length\n",
    "        samples[i] = sample[:,start:end]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instrument(program=0, is_drum=False, name=\"Right Hand\")\n",
      "Instrument(program=0, is_drum=False, name=\"Left Hand\")\n",
      "(128, 3888)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "midi_data = pretty_midi.PrettyMIDI('data/Zelda_Overworld.mid')\n",
    "\n",
    "mat = generate_combine_piano_roll(midi_data, FS)\n",
    "print(mat.shape)\n",
    "cax = plt.matshow(mat, aspect=\"auto\")\n",
    "plt.colorbar(cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 51200)\n"
     ]
    }
   ],
   "source": [
    "length = 512\n",
    "samples = split_sample(mat, 512, 100)\n",
    "new_track = np.concatenate(samples, axis=1)\n",
    "#print(new_track.shape)\n",
    "#pm = piano_roll_to_pretty_midi(new_track * 75, fs=FS, program=0)\n",
    "#pm.write(\"pianoroll.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piano_roll_to_pretty_midi(piano_roll, fs=100, program=0):\n",
    "    '''Convert a Piano Roll array into a PrettyMidi object\n",
    "     with a single instrument.\n",
    "    Parameters\n",
    "    ----------\n",
    "    piano_roll : np.ndarray, shape=(128,frames), dtype=int\n",
    "        Piano roll of one instrument\n",
    "    fs : int\n",
    "        Sampling frequency of the columns, i.e. each column is spaced apart\n",
    "        by ``1./fs`` seconds.\n",
    "    program : int\n",
    "        The program number of the instrument.\n",
    "    Returns\n",
    "    -------\n",
    "    midi_object : pretty_midi.PrettyMIDI\n",
    "        A pretty_midi.PrettyMIDI class instance describing\n",
    "        the piano roll.\n",
    "    '''\n",
    "    notes, frames = piano_roll.shape\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=program)\n",
    "\n",
    "    # pad 1 column of zeros so we can acknowledge inital and ending events\n",
    "    piano_roll = np.pad(piano_roll, [(0, 0), (1, 1)], 'constant')\n",
    "\n",
    "    # use changes in velocities to find note on / note off events\n",
    "    velocity_changes = np.nonzero(np.diff(piano_roll).T)\n",
    "\n",
    "    # keep track on velocities and note on times\n",
    "    prev_velocities = np.zeros(notes, dtype=int)\n",
    "    note_on_time = np.zeros(notes)\n",
    "\n",
    "    for time, note in zip(*velocity_changes):\n",
    "        # use time + 1 because of padding above\n",
    "        velocity = piano_roll[note, time + 1]\n",
    "        time = time / fs\n",
    "        if velocity > 0:\n",
    "            if prev_velocities[note] == 0:\n",
    "                note_on_time[note] = time\n",
    "                prev_velocities[note] = velocity\n",
    "        else:\n",
    "            pm_note = pretty_midi.Note(\n",
    "                velocity=prev_velocities[note],\n",
    "                pitch=note,\n",
    "                start=note_on_time[note],\n",
    "                end=time)\n",
    "            instrument.notes.append(pm_note)\n",
    "            prev_velocities[note] = 0\n",
    "    pm.instruments.append(instrument)\n",
    "    return pm\n",
    "pm = piano_roll_to_pretty_midi(mat * 75, fs=FS, program=0)\n",
    "pm.write(\"pianoroll.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN():\n",
    "    def __init__(self, img_rows, img_cols, channels):\n",
    "        # Input shape\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channels = channels\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 4 * 16, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((4, 16, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.add(UpSampling2D((4,4)))\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(UpSampling2D((4,4)))\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "        print(\"Generator model\")\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        print(\"Discriminator model\")\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, X_train, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        #X_train = train_data / 127.5 - 1.\n",
    "        #X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select random batch\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        n_images = 1\n",
    "        noise = np.random.normal(0, 1, (n_images, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        print(\"Generated shape\", gen_imgs.shape)\n",
    "        img = gen_imgs.reshape(128, 512)\n",
    "        \n",
    "        img[img < 0.3] = 0 # Remove some notes\n",
    "        \n",
    "        pm = piano_roll_to_pretty_midi(img * 75, fs=FS, program=0)\n",
    "        pm.write(\"output/pianoroll-%d.mid\" % epoch)\n",
    "        \n",
    "        cax = plt.matshow(img, aspect=\"auto\")\n",
    "        plt.colorbar(cax)\n",
    "        plt.savefig(\"output/pianoroll-%d.png\" % epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_147 (Conv2D)          (None, 64, 256, 32)       320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_89 (LeakyReLU)   (None, 64, 256, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 64, 256, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_148 (Conv2D)          (None, 32, 128, 64)       18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPaddi (None, 33, 129, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 33, 129, 64)       256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_90 (LeakyReLU)   (None, 33, 129, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 33, 129, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_149 (Conv2D)          (None, 17, 65, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 17, 65, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_91 (LeakyReLU)   (None, 17, 65, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 17, 65, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_150 (Conv2D)          (None, 17, 65, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 17, 65, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_92 (LeakyReLU)   (None, 17, 65, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 17, 65, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 282880)            0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 282881    \n",
      "=================================================================\n",
      "Total params: 672,513\n",
      "Trainable params: 671,617\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Generator model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_46 (Dense)             (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "reshape_23 (Reshape)         (None, 4, 16, 128)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_54 (UpSampling (None, 8, 32, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_151 (Conv2D)          (None, 8, 32, 128)        147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_109 (Bat (None, 8, 32, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 8, 32, 128)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_55 (UpSampling (None, 32, 128, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_152 (Conv2D)          (None, 32, 128, 64)       73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_110 (Bat (None, 32, 128, 64)       256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 32, 128, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_153 (Conv2D)          (None, 32, 128, 1)        577       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_56 (UpSampling (None, 128, 512, 1)       0         \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 128, 512, 1)       0         \n",
      "=================================================================\n",
      "Total params: 1,050,113\n",
      "Trainable params: 1,049,729\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "(n_samples, pitch_level, time_span) = samples.shape\n",
    "train_data = samples.reshape(n_samples, pitch_level, time_span, 1)\n",
    "dcgan = DCGAN(pitch_level,time_span,1)\n",
    "dcgan.train(train_data, epochs=45, batch_size=32, save_interval=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
