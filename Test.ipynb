{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combine_piano_roll(midi_data, fs, pitch_offset, pitch_length):\n",
    "    mat = None\n",
    "    for inst in midi_data.instruments:\n",
    "        print(inst)\n",
    "        if (inst.is_drum == False):\n",
    "            if (mat is None):\n",
    "                mat = inst.get_piano_roll(fs=fs)\n",
    "            else:\n",
    "                mat += inst.get_piano_roll(fs=fs)\n",
    "\n",
    "    mat[mat > 0] = 1\n",
    "    return mat[pitch_offset:pitch_length + pitch_offset,:]\n",
    "\n",
    "# Split into 10 seconds chunks\n",
    "def split_sample(sample, length, sliding_factor):\n",
    "    (pitch_level, time_steps) = sample.shape\n",
    "    n_samples = int(time_steps / length * sliding_factor)\n",
    "    print(n_samples)\n",
    "    samples = np.zeros((n_samples, pitch_level, length))\n",
    "    for i in range(0, n_samples):\n",
    "        start = int(i * length / sliding_factor)\n",
    "        end = start + length\n",
    "        samples[i] = sample[:,start:end]\n",
    "    return samples\n",
    "\n",
    "def split_sample(sample, length, n_samples):\n",
    "    (pitch_level, time_steps) = sample.shape\n",
    "    samples = np.zeros((n_samples, pitch_level, length))\n",
    "    max_start = time_steps - length\n",
    "    for i in range(0, n_samples):\n",
    "        start = int(i * max_start / n_samples)\n",
    "        end = start + length\n",
    "        samples[i] = sample[:,start:end]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instrument(program=0, is_drum=False, name=\"Right Hand\")\n",
      "Instrument(program=0, is_drum=False, name=\"Left Hand\")\n",
      "(64, 3888)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzUAAACVCAYAAABhGNSfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHNJJREFUeJzt3X2wZVddp/HnmyZJy2sSGkKTbkmQRklRkjBtAkUVBnlJw1iEKQN2psQMFWxGiQMCA0EpYKKOqOVrTQRbiEQKDTHK0IMtbYyh0Clp0kiIJCGmiZi0yRBCAqJUkn75zR9ndzz35tzzcu952/c+n6pd9+x19l57nbXXXfeus152qgpJkiRJaqtjZp0ASZIkSVoJGzWSJEmSWs1GjSRJkqRWs1EjSZIkqdVs1EiSJElqNRs1kiRJklptKo2aJNuS3Jpkf5JLpnHNtSDJV5P8fZIbkuxrwk5Kck2S25qfJzbhSfLbzT24MclzZ5v6+Zfk8iT3JPlSV9jI+Zvkwub425JcOIvP0gZL5Pd7k/xzU8ZvSPKKrvfe2eT3rUnO7Qq3vhlCks1JrktyS5KbkrypCbeMj1mfvLZ8T0CS9Uk+l+SLTX7/jyb8tCR7m3L6sSTHNeHHN/v7m/dP7Yqr533Qv+uT3x9O8o9d5fuMJty6RJNRVRPdgHXAV4CnA8cBXwROn/R118IGfBXYsCjsV4BLmteXAL/cvH4F8OdAgOcBe2ed/nnfgBcCzwW+tNz8BU4Cbm9+nti8PnHWn20etyXy+73A23oce3pTlxwPnNbUMeusb0bK743Ac5vXjwP+oclXy/j08tryPZn8DvDY5vWxwN6mzF4FbG/CPwD8ZPP6p4APNK+3Ax/rdx9m/fnmbeuT3x8Gzu9xvHWJ20S2afTUnAXsr6rbq+oh4ErgvClcd606D7iieX0F8Kqu8D+ojs8CJyTZOIsEtkVVfQa4b1HwqPl7LnBNVd1XVfcD1wDbJp/69lkiv5dyHnBlVT1YVf8I7KdT11jfDKmq7q6qv2tefxu4BTgFy/jY9cnrpVi+V6Apo//a7B7bbAX8EHB1E764bB8t81cDL04Slr4P6tInv5diXaKJmEaj5hTgzq79A/SvzDW8Av4iyeeT7GjCTq6qu6HzhxR4chPufRiPUfPXfF+5i5shCpcfHQqF+T1WzXCbM+l8w2oZn6BFeQ2W74lIsi7JDcA9dP45/grwzao61BzSnXcP52vz/reAJ2J+D21xflfV0fL9i035/o0kxzdhlm9NxDQaNekR1q8Fr+G9oKqeC7wceGOSF/Y51vswWUvlr/m+Mu8Hvgc4A7gb+LUm3PwekySPBf4EeHNV/Uu/Q3uEmecj6JHXlu8JqarDVXUGsIlO78qzeh3W/DS/V2hxfid5NvBO4PuAH6AzpOwdzeHmtyZiGo2aA8Dmrv1NwF1TuO6qV1V3NT/vAT5Op+L+2tFhZc3Pe5rDvQ/jMWr+mu8rUFVfa/5YHgF+j38f+mF+j0GSY+n8k/3RqvrTJtgyPgG98tryPXlV9U3g03TmbpyQ5FHNW91593C+Nu8/gc5QWPN7RF35va0ZdllV9SDw+1i+NWHTaNRcD2xpVh05js4kvF1TuO6qluQxSR539DXwMuBLdPL26IohFwKfaF7vAn68WXXkecC3jg4x0UhGzd89wMuSnNgMLXlZE6YhLJr39Z/olHHo5Pf2ZtWi04AtwOewvhlaM2fgQ8AtVfXrXW9Zxsdsqby2fE9GkiclOaF5/V3AS+jMY7oOOL85bHHZPlrmzwf+qqqKpe+DuiyR31/u+nIkdOYvdZdv6xKN3aMGH7IyVXUoycV0CuY64PKqumnS110DTgY+3qkreBTwh1X1qSTXA1cluQi4A3h1c/xuOiuO7Ae+A7xu+klulyR/BJwDbEhyAHgP8D5GyN+qui/Jz9P5ZwTg0qoadjL8mrJEfp/TLANadFb7ewNAVd2U5CrgZuAQ8MaqOtzEY30znBcArwX+vhkLD/CzWMYnYam8vsDyPREbgSuSrKPz5e1VVfXJJDcDVyb5BeALdBqaND8/kmQ/nR6a7dD/PmiBpfL7r5I8ic6wshuA/9ocb12iiUjnywhJkiRJaqepPHxTkiRJkibFRo0kSZKkVrNRI0mSJKnVbNRIkiRJajUbNZIkSZKmIsnlSe5J8qUl3k+S306yP8mNSZ47TLwratQk2Zbk1uailwxx/I6VXE+jMb+ny/yeHvN6uszv6TK/p8v8ni7zW8CHgW193n85nedCbQF2AO8fJtJlN2qa9cgvay58Op319k8fcJoFebrM7+kyv6fHvJ4u83u6zO/pMr+ny/xe46rqM3SeCbWU84A/qI7PAicselhxTyvpqTkL2F9Vt1fVQ8CVTSIkSZIkaTlOAe7s2j/QhPX1qDFf8Ox+J6xj3X94fE7yaZ9Tsp5HY35Pj/k9Peb1dJnf02V+T5f5PV3m99Ie4N94qB7MrNMxinNf9Jj6xn2HF4R9/sYHbwIe6AraWVU7R4i2Vx4MLDMradQMdcFm7OQO6BTks/PiFVxSkiRJWn321rWzTsLI7r3vMHv3bFoQduzGrzxQVVtXEO0BYHPX/ibgrkEnrWT42VAXrKqdVbW1qrYey/EruJwkSZKkeVEUD9bBBdsY7AJ+vFkF7XnAt6rq7kEnraSn5npgS5LTgH8GtgP/eQXxSZIkSWqJojhYR0Y6J8kfAecAG5IcAN4DHAtQVR8AdgOvAPYD3wFeN0y8y27UVNWhJBcDe4B1wOVVddNy45MkSZLUHgUcZLRGTVVdMOD9At44alpW0lNDVe2m05qSJEmStIYcoXhgxJ6aSVlRo0aSJEnS2lQFB+dkLTsbNZIkSZJGVoSDNR+rUNuokSRJkjSyAh5a0WLK42OjRpIkSdLIjhAeqPloTsxHKiRJkiS1SgEHy54aSZIkSS3VmVMzH82J+UiFJEmSpFapcviZJEmSpBYrwkM2aiRJkiS1VWdOzbpZJwNg8BpsSS5Pck+SL3WFnZTkmiS3NT9PnGwyJUmSJM2To3NqurdZGWa5gg8D2xaFXQJcW1VbgGubfUmSJElrRGdJ52MXbLMysFFTVZ8B7lsUfB5wRfP6CuBVY06XJEmSpDlWFQ7WugXbrCy3j+jkqroboKruTvLkMaZJkiRJ0pwrmJuFAib+tJwkO5LsS7LvIA9O+nKSJEmSpuAI4cEjxy7YhpFkW5Jbk+xP8ohpLEm+O8l1Sb6Q5MYkrxgU53IbNV9LsrG56EbgnqUOrKqdVbW1qrYey/HLvJwkSZKkedJZKGC04WdJ1gGXAS8HTgcuSHL6osPeBVxVVWcC24HfGRTvchs1u4ALm9cXAp9YZjySJEmSWmiZc2rOAvZX1e1V9RBwJZ35+guiBh7fvH4CcNegSAcOgkvyR8A5wIYkB4D3AO8DrkpyEXAH8OphPoEkSZKk1aEIDww55KzLKcCdXfsHgLMXHfNe4C+S/DTwGOAlgyId2KipqguWeOvFg86VJEmStDot8fDNDUn2de3vrKqdXftZIqpuFwAfrqpfS/J84CNJnl1VR5ZKy3wsVyBJkiSpVYpw6JGNmnuramuf0w4Am7v2N/HI4WUX0Twns6r+Nsl6YAN95vFPfPUzSZIkSatPFRw8csyCbQjXA1uSnJbkODoLAexadMwdNKPCkjwLWA98vV+k9tRIkiRJGllnSefRmhNVdSjJxcAeYB1weVXdlORSYF9V7QLeCvxekp+hMzTtv1TV4iFqC9iokSRJkrQMPYefDVRVu4Hdi8Le3fX6ZuAFo8Rpo0aSJEnSyDrDz0Zv1EyCjRpJkiRJIztCeMhGjSRJkqTWqnDIRo0kSZKktirgUM3HYsoDU5Fkc5LrktyS5KYkb2rCT0pyTZLbmp8nTj65kiRJkuZBAYeOHLNgm5VhrnwIeGtVPQt4HvDGJKcDlwDXVtUW4NpmX5IkSdIaUNWZU9O9zcrARk1V3V1Vf9e8/jZwC3AKcB5wRXPYFcCrJpVISZIkSfNlnnpqRppTk+RU4ExgL3ByVd0NnYZPkiePPXWSJEmS5lIRDs+wIdNt6EZNkscCfwK8uar+Jcmw5+0AdgCs59HLSaMkSZKkOTNPz6kZqmmV5Fg6DZqPVtWfNsFfS7KxeX8jcE+vc6tqZ1Vtraqtx3L8ONIsSZIkaeY6PTXd26wMs/pZgA8Bt1TVr3e9tQu4sHl9IfCJ8SdPkiRJ0jyqgsNHsmCblWGGn70AeC3w90luaMJ+FngfcFWSi4A7gFdPJomSJEmS5k2RuRl+NrBRU1V/AyzV7HrxeJMjSZIkqS2OzLB3ptt8LFcgSZIkqVU6w89Gn1OTZFuSW5PsT9LzWZdJXpPk5iQ3JfnDQXGOtKSzJEmSJB01ak9NknXAZcBLgQPA9Ul2VdXNXcdsAd4JvKCq7h/m0TH21EiSJEkaWdWyVj87C9hfVbdX1UPAlcB5i475CeCyqrq/c53qucpyN3tqhrTnrht6hp/71DMWvHd0/9ynnjGtpGlMjt63Qffae6t5t1QZPmo1lOV+n7H7c3X/Xrf5865Va6Esa/XqLpuLy3Kv/x+f+f3fmWr6xqVGn1NzCnBn1/4B4OxFxzwTIMn/BdYB762qT/WLNFU1akKW7fE5qc6OawtIkiRJ3fbWtfxL3Tcfs+6HdPz3nFKb/udPLQi7ffu7/gm4tytoZ1XtPLqT5NXAuVX1+mb/tcBZVfXTXcd8EjgIvAbYBPw18Oyq+uZSabGnRpIkSdLoCurwI9ph91bV1j5nHQA2d+1vAu7qccxnq+og8I9JbgW2ANcvFalzaiRJkiQtQ6gjC7chXA9sSXJakuOA7cCuRcf8b+BFAEk20BmOdnu/SG3USJIkSRpdMXKjpqoOARcDe4BbgKuq6qYklyZ5ZXPYHuAbSW4GrgP+e1V9o1+8A4efJVkPfAY4vjn+6qp6T5LT6KxWcBLwd8BrmxUMJmLxZM9ekwcXT8aa14mDTmpcvby3WkuGWVyj+9he4fPC393Vy3srTViNPg2oqnYDuxeFvbvrdQFvabahDNNT8yDwQ1X1HOAMYFuS5wG/DPxGVW0B7gcuGvaikiRJklqumVPTvc3KSKufJXk08DfATwJ/Bjylqg4leT6dpdbO7Xf+rFY/G/RtIjyyl+do2Lz3+khqp17Le64lK62X11p+SZq8WdfLrVz97NRN9ZR3vWlB2B0/8fbPD1goYCKGatQ0T/78PPAMOk8A/VU6KxI8o3l/M/DnVfXsfvFsfc76+tyezT3fa9MwhWF1N4j6NZZsOLXP4nu21P303mrejfK8l6Xea4ul6uHF+238bPJvrtqvlY2ap22qjT+3sFHzT2+YTaNmqIUCqupwVZ1BZ8m1s4Bn9Tqs17lJdiTZl2Tf179xePkplSRJkjRHAocXbbNKyagP30zyHuA7wDtoyfCztnBIxerNg9X6uaTVzt/d1ZsHq/Vzqb1a2VPz3Ztr4zvevCDsny5+23z21CR5UpITmtffBbyEzvJr1wHnN4ddCHxiUomUJEmSNH9yZOE2KwOXdAY2Alc082qOobOW9CebdaOvTPILwBeAD00wnWuC3xiNngfDzgeYtXlKi+ZTW8ryWmPej69enre8nLf0aP60pSzPWoZ74ObEDWzUVNWNwJk9wm+nM79GkiRJ0lpTwAx7Z7oN01Mj+rfWh1ludNjW/moY4zvqZ1jOCkSTWL1mmAcJLvXZ+j0MdnH8WjtG6X0Zd1nuZzUsizzKqm0rrZdXg3mol5dT5pZbltfS31yNZhz18rDlpvu4XitILv49e+b3f2dgnPNolkPOuo28UMBKuFDAdI3zH/9+/8z3Wz6z3/WH/SPZa1lZ/whpUhwGpkkaVx3W75+qxfVyr6Xnx5k+62VN2lqpl9u4UMD6TZtr05t+ZkHYV97+1pksFGBPjSRJkqRlyQyXce5mT41WrXl8iKtDHbQc81iW1xJ/b8dnHsuy91fLMYmy3MqemlM213e/8S0Lwm77ubfYUyNJkiSpRZxTszwr+UalLd/GjNr6H/S5xjE5s3sy5jALI/S7/qjjr+fxm72VGOXztKXMam2zXu59/CTr5e55MkvNn5nUvJhefx/abtTPvxo+s+ZPW3tqnvaGhT01//CewT01SbYBvwWsAz5YVe9b4rjzgT8GfqCq9vWLc+DDNyVJkiTpEWr0h282z768DHg5cDpwQZLTexz3OOC/AXuHSUrremqkcfHbtqVN6pvYQcusTqpXbtCysL3S0iaWZbXRUksxW5Z7m3b92OsRB9bLvY2rLLexp+a7nrq5Tn39wp6aL/98/56aJM8H3ltV5zb77wSoql9adNxvAn8JvA1426Cemqk2arY+Z319bs/mnu/1Gp7UHb7UEKbFcQw6d9R/qlY6rKI77uUcN0ocKxnqMOk/JPMwhGzcS1wPE9c4ntvgH/n2mNYQnkmU5V761bmL68dBz2rqV7dOq14eVz1kvTz+NMxLvTyue6v50aZ6uZWNmo2b67SLFjZqbvnFgY2a84FtVfX6Zv+1wNlVdXHXMWcC76qqH0nyaYZo1Aw9/CzJuiRfSPLJZv+0JHuT3JbkY0mOGzYuSZIkSe2Xwws3YEOSfV3bjsWn9Ijm4V6WJMcAvwG8daR0DNtTk+QtwFbg8VX1w0muAv60qq5M8gHgi1X1/n5xOPxMaqdhnuq9Gq45qtU4YVrS/JtV/Wi9PFmt7Kl5yuZ6+oULe2pu/pWVDT9L8gTgK8C/Nqc8BbgPeGW/3pqhemqSbAL+I/DBZj/ADwFXN4dcAbxqmLgkSZIkrQ6jLhQAXA9saUZ9HQdsB3YdfbOqvlVVG6rq1Ko6FfgsAxo0MPxzan4TeDvwuGb/icA3q+pQs38AOGXIuLSEfmN0xzH3Yqn32zw2eDljwsc5hntY47i3MPkJ+0tdY9LzyoZNxzSuO4pJTZqd57K81lgvj64tZXnS93Y56ellnHVy93WslwdrS1meqXp4yNnwp1QdSnIxsIfOks6XV9VNSS4F9lXVrv4x9DawUZPkh4F7qurzSc45GtwrjUucvwPYAbCeRy8njZIkSZLmTIAsY82xqtoN7F4U9u4ljj1nqLQMmlOT5JeA1wKHgPXA44GPA+cCT2laWwvGxi3FOTWTN+hbhX4rFM3q2wW/CRleG5bAnNWKSvOwktNio/aIaXUapl4eZvXOabJeHp718uBrTvO6g8xzvdzGOTWPPnlzbdm+cE7Njb89+OGbkzDSks5NT83bmoUC/hj4k66FAm6sqt/pd76NmsFW2h2+ls17/nhv59M8/uG1PLSH96q/ec8f6+X5NI/18jS0slHz5M31zNcsbNR88bLZNGqGXtK5h3cAb0myn84cmw+NJ0mSJEmS2mAZCwVMJh3TfPimPTUrN6/fHI1rqMIwk2pHuca8meW3gvNadubNPA9N0GzM+iGZy2W9PJxZ1cttz7dpWiv1cit7ap60ub7vRxb21Hzhd2fTUzPs6meSJEmS9LAw296ZbvbUaFVZK9/mDGOtjkleLSzLWi0sy/9uHhc00XCm8eDRNvbUPGbD5nrWeT+zIOzzl7/VnhpJkiRJ7TEvPTU2aubQKMtDHjWJb3yWu0zlSsdfr+RbvVHyYR6WSh3GctM4joekjSOufvEujn9S32JO65vicY6Rb0NZXktGrQ8ndU+slyejbfXytB76Ocke/7bVy6Oev5bq5Xlp1Dj8bJVY6S/P4vPHEd9S1sov+bjMQ8U4jW73ebjmqBzip36sl1evWdfLs6ofrZcnq43Dzx77xM317JcvHH6296MOP5MkSZLUIjkyvQ6Sfuyp0ZrR5m9vpG6WZa0WlmWtFuMoy63sqTlpc33/S9+8IOxvr3qbPTWSJEmS2mNe5tQM1ahJ8lXg28Bh4FBVbU1yEvAx4FTgq8Brqur+ySRTw1juGN+j5632B4G1+XOt9nuj0VgO2mMc9fJqvt9t/myr/d5oNGu2LBTk8HwMPztmhGNfVFVndHUnXQJcW1VbgGubfUmSJElrQKrIkYXbUOcl25LcmmR/kke0IZK8JcnNSW5Mcm2Spw2RlsEXb3pqtlbVvV1htwLnVNXdSTYCn66q7+0Xj3NqpPnQtqU023JdSVquQUvej/s61svzp41zah53wqY684VvWhD21//n7X3n1CRZB/wD8FLgAHA9cEFV3dx1zIuAvVX1nSQ/SafN8aP90jLsnJoC/iJJAb9bVTuBk6vqboCmYfPkIePSBM3LM240Gct9RsUo763UrJ6Y7ZO6Na+sl1c36+XB15zmdTVlBTk08vCzs4D9VXU7QJIrgfOAhxs1VXVd1/GfBX5sUKTDNmpeUFV3NQ2Xa5J8edhUJ9kB7ABYz6OHPU2SJEnSnFvGks6nAHd27R8Azu5z/EXAnw+KdKhGTVXd1fy8J8nH6bSwvpZkY9fws3uWOHcnsBM6w8+GuZ6Wz29CVrc23N9ZpbENeaO1ybK5urXh/s4ijW3IF41B9Vz9bEOSfV37O5v2wFG9htj1bCMk+TFgK/CDg5IysFGT5DHAMVX17eb1y4BLgV3AhcD7mp+fGBSXJEmSpNUh9Fz97N4Bz6k5AGzu2t8E3PWIuJOXAD8H/GBVPTgoLcOsfnYy8DdJvgh8DvizqvoUncbMS5PcRmeiz/uGiEvSjCxnXL8kaTL23HWD9bLar4ocPrJgG8L1wJYkpyU5DthOp7PkYUnOBH4XeGVV9RwNttjAnppmEs9zeoR/A3ApM0mSJGmNGnVOTVUdSnIxsAdYB1xeVTcluRTYV1W7gF8FHgv8cRKAO6rqlf3iHXahAEkt48ozkjRfXKVRq84yH75ZVbuB3YvC3t31+iWjxmmjRlql/IMpSfPFelmr0ZBDzibORo0kSZKkkaVqWT01k2CjRpIkSdLyHLGnRpIkSVJbFeSQjRpJkiRJbVVlT40kSZKkdnNOjSRJkqT2KsDVzyRJkiS1V8Hhw7NOBADHDHNQkhOSXJ3ky0luSfL8JCcluSbJbc3PEyedWEmSJElzoppGTfc2I0M1aoDfAj5VVd8HPAe4BbgEuLaqtgDXNvuSJEmS1oKjw8+6txkZ2KhJ8njghcCHAKrqoar6JnAecEVz2BXAqyaVSEmSJEnzpl09NU8Hvg78fpIvJPlgkscAJ1fV3QDNzydPMJ2SJEmS5knRqkbNo4DnAu+vqjOBf2OEoWZJdiTZl2TfQR5cZjIlSZIkzZdqz/Az4ABwoKr2NvtX02nkfC3JRoDm5z29Tq6qnVW1taq2Hsvx40izJEmSpFkrqMOHF2yzMrBRU1X/D7gzyfc2QS8GbgZ2ARc2YRcCn5hICiVJkiTNnyo4dGjhNoQk25LcmmR/kkeMAEtyfJKPNe/vTXLqoDiHfU7NTwMfTXIccDvwOjoNoquSXATcAbx6yLgkSZIktV6N3DuTZB1wGfBSOiPCrk+yq6pu7jrsIuD+qnpGku3ALwM/2i/eoRo1VXUDsLXHWy8e5nxJkiRJq8zRhQJGcxawv6puB0hyJZ1VlbsbNecB721eXw38rySpqloq0mGfUyNJkiRJD6sqjhw8tGAbwinAnV37B5qwnsdU1SHgW8AT+0U67PCzsfg29//rX9bVt07zmmvcBuDeWSdiDTG/p8e8ni7ze7rM7+kyv6fL/F7a02adgFF9m/v3/OWRqzYsCl6fZF/X/s6q2tm1nx5RLe6BGeaYBabaqAFurapew9g0AUn2md/TY35Pj3k9Xeb3dJnf02V+T5f5vbpU1bZlnHYA2Ny1vwm4a4ljDiR5FPAE4L5+kTr8TJIkSdK0XA9sSXJaswjZdjqrKnfrXmX5fOCv+s2ngen31EiSJElao6rqUJKLgT3AOuDyqropyaXAvqraBXwI+EiS/XR6aLYPinfajZqdgw/RGJnf02V+T495PV3m93SZ39Nlfk+X+S2qajewe1HYu7teP8CIj4vJgJ4cSZIkSZprzqmRJEmS1Go2aiRJkiS1mo0aSZIkSa1mo0aSJElSq9mokSRJktRqNmokSZIktZqNGkmSJEmt9v8BWkckOZa9pT4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x144 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "midi_data = pretty_midi.PrettyMIDI('data/Zelda_Overworld.mid')\n",
    "\n",
    "FS = 50\n",
    "PITCH_OFFSET = 32\n",
    "PITCH_LENGTH = 64\n",
    "mat = generate_combine_piano_roll(midi_data, FS, PITCH_OFFSET, PITCH_LENGTH)\n",
    "print(mat.shape)\n",
    "cax = plt.matshow(mat, aspect=\"auto\")\n",
    "plt.colorbar(cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 64, 553)\n"
     ]
    }
   ],
   "source": [
    "LENGTH = 553\n",
    "samples = split_sample(mat, LENGTH, 100)\n",
    "new_track = np.concatenate(samples, axis=1)\n",
    "print(samples.shape)\n",
    "#print(new_track.shape)\n",
    "#pm = piano_roll_to_pretty_midi(new_track * 75, fs=FS, program=0)\n",
    "#pm.write(\"pianoroll.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piano_roll_to_pretty_midi(piano_roll, fs=100, program=0):\n",
    "    '''Convert a Piano Roll array into a PrettyMidi object\n",
    "     with a single instrument.\n",
    "    Parameters\n",
    "    ----------\n",
    "    piano_roll : np.ndarray, shape=(128,frames), dtype=int\n",
    "        Piano roll of one instrument\n",
    "    fs : int\n",
    "        Sampling frequency of the columns, i.e. each column is spaced apart\n",
    "        by ``1./fs`` seconds.\n",
    "    program : int\n",
    "        The program number of the instrument.\n",
    "    Returns\n",
    "    -------\n",
    "    midi_object : pretty_midi.PrettyMIDI\n",
    "        A pretty_midi.PrettyMIDI class instance describing\n",
    "        the piano roll.\n",
    "    '''\n",
    "    notes, frames = piano_roll.shape\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=program)\n",
    "\n",
    "    # pad 1 column of zeros so we can acknowledge inital and ending events\n",
    "    piano_roll = np.pad(piano_roll, [(0, 0), (1, 1)], 'constant')\n",
    "\n",
    "    # use changes in velocities to find note on / note off events\n",
    "    velocity_changes = np.nonzero(np.diff(piano_roll).T)\n",
    "\n",
    "    # keep track on velocities and note on times\n",
    "    prev_velocities = np.zeros(notes, dtype=int)\n",
    "    note_on_time = np.zeros(notes)\n",
    "\n",
    "    for time, note in zip(*velocity_changes):\n",
    "        # use time + 1 because of padding above\n",
    "        velocity = piano_roll[note, time + 1]\n",
    "        time = time / fs\n",
    "        if velocity > 0:\n",
    "            if prev_velocities[note] == 0:\n",
    "                note_on_time[note] = time\n",
    "                prev_velocities[note] = velocity\n",
    "        else:\n",
    "            pm_note = pretty_midi.Note(\n",
    "                velocity=prev_velocities[note],\n",
    "                pitch=note,\n",
    "                start=note_on_time[note],\n",
    "                end=time)\n",
    "            instrument.notes.append(pm_note)\n",
    "            prev_velocities[note] = 0\n",
    "    pm.instruments.append(instrument)\n",
    "    return pm\n",
    "pm = piano_roll_to_pretty_midi(mat * 75, fs=FS, program=0)\n",
    "pm.write(\"pianoroll.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.merge import _Merge\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from functools import partial\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, img_rows, img_cols, channels, batch_size):\n",
    "        # Input shape\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channels = channels\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        # TODO: Deconv, kernel size\n",
    "        model.add(Dense(64 * 2 * 4, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        \n",
    "        model.add(Reshape((2, 4, 64)))\n",
    "        model.add(Conv2DTranspose(filters=64, kernel_size=(4, 64), strides=(2, 1))) #output_padding=(1,1)\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2DTranspose(filters=64, kernel_size=4, strides=2))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2DTranspose(filters=64, kernel_size=4, strides=2))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2DTranspose(filters=64, kernel_size=(3, 4), strides=2))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2DTranspose(filters=self.channels, kernel_size=4, strides=1))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.add(UpSampling2D((2,2)))\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.add(UpSampling2D((2,2)))\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.add(UpSampling2D((2,2)))\n",
    "        model.add(Conv2D(32, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.add(UpSampling2D((2,2)))\n",
    "        model.add(Conv2D(32, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.add(UpSampling2D((2,2)))\n",
    "        model.add(Conv2D(32, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        \"\"\"\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "        print(\"Generator model\")\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "    \n",
    "    \n",
    "    def build_discriminator(self, final_activation='sigmoid'):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=(4,89), strides=2, input_shape=self.img_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=(4,1), strides=2, padding=\"same\"))\n",
    "        #model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=(4,1), strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        #model.add(Conv2D(256, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        #model.add(BatchNormalization(momentum=0.8))\n",
    "        #model.add(LeakyReLU(alpha=0.2))\n",
    "        #model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation=final_activation))\n",
    "\n",
    "        print(\"Discriminator model\")\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "        \n",
    "    \n",
    "    def save_imgs(self, epoch):\n",
    "        n_images = 1\n",
    "        noise = np.random.normal(0, 1, (n_images, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        print(\"Generated shape\", gen_imgs.shape)\n",
    "        img = gen_imgs.reshape(128, 512)\n",
    "        \n",
    "        cax = plt.matshow(img, aspect=\"auto\")\n",
    "        plt.colorbar(cax)\n",
    "        plt.savefig(\"output/pianoroll-%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "        img[img < 0.1] = 0 # Remove some notes\n",
    "        img[img >= 0.1] = 1 # Binarize the rest\n",
    "        \n",
    "        pm = piano_roll_to_pretty_midi(img * 75, fs=FS, program=0)\n",
    "        pm.write(\"output/pianoroll-%d.mid\" % epoch)\n",
    "        \n",
    "        cax = plt.matshow(img, aspect=\"auto\")\n",
    "        plt.colorbar(cax)\n",
    "        plt.savefig(\"output/pianoroll-%d-binarised.png\" % epoch)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large amount of credit goes to:\n",
    "# https://github.com/keras-team/keras-contrib/blob/master/examples/improved_wgan.py\n",
    "# which I've used as a reference for this implementation\n",
    "\n",
    "class RandomWeightedAverage(_Merge):\n",
    "    \"\"\"Provides a (random) weighted average between real and generated image samples\"\"\"\n",
    "    def __init__(self, batch_size):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def _merge_function(self, inputs):\n",
    "        alpha = K.random_uniform((self.batch_size, 1, 1, 1))\n",
    "        return (alpha * inputs[0]) + ((1 - alpha) * inputs[1])\n",
    "\n",
    "class WGANGP(GAN):\n",
    "    def __init__(self, img_rows, img_cols, channels, batch_size):\n",
    "        super().__init__(img_rows, img_cols, channels, batch_size)\n",
    "        \n",
    "        # Following parameter and optimizer set as recommended in paper\n",
    "        self.n_critic = 5\n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "\n",
    "        # Build the generator and critic\n",
    "        self.generator = self.build_generator()\n",
    "        self.critic = self.build_discriminator(final_activation='tanh')\n",
    "\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #       for the Critic\n",
    "        #-------------------------------\n",
    "\n",
    "        # Freeze generator's layers while training critic\n",
    "        self.generator.trainable = False\n",
    "\n",
    "        # Image input (real sample)\n",
    "        real_img = Input(shape=self.img_shape)\n",
    "\n",
    "        # Noise input\n",
    "        z_disc = Input(shape=(self.latent_dim,))\n",
    "        # Generate image based of noise (fake sample)\n",
    "        fake_img = self.generator(z_disc)\n",
    "\n",
    "        # Discriminator determines validity of the real and fake images\n",
    "        fake = self.critic(fake_img)\n",
    "        valid = self.critic(real_img)\n",
    "\n",
    "        # Construct weighted average between real and fake images\n",
    "        interpolated_img = RandomWeightedAverage(self.batch_size)([real_img, fake_img])\n",
    "        # Determine validity of weighted sample\n",
    "        validity_interpolated = self.critic(interpolated_img)\n",
    "\n",
    "        # Use Python partial to provide loss function with additional\n",
    "        # 'averaged_samples' argument\n",
    "        partial_gp_loss = partial(self.gradient_penalty_loss,\n",
    "                          averaged_samples=interpolated_img)\n",
    "        partial_gp_loss.__name__ = 'gradient_penalty' # Keras requires function names\n",
    "\n",
    "        self.critic_model = Model(inputs=[real_img, z_disc],\n",
    "                            outputs=[valid, fake, validity_interpolated])\n",
    "        self.critic_model.compile(loss=[self.wasserstein_loss,\n",
    "                                              self.wasserstein_loss,\n",
    "                                              partial_gp_loss],\n",
    "                                        optimizer=optimizer,\n",
    "                                        loss_weights=[1, 1, 10])\n",
    "        #-------------------------------\n",
    "        # Construct Computational Graph\n",
    "        #         for Generator\n",
    "        #-------------------------------\n",
    "\n",
    "        # For the generator we freeze the critic's layers\n",
    "        self.critic.trainable = False\n",
    "        self.generator.trainable = True\n",
    "\n",
    "        # Sampled noise for input to generator\n",
    "        z_gen = Input(shape=(100,))\n",
    "        # Generate images based of noise\n",
    "        img = self.generator(z_gen)\n",
    "        # Discriminator determines validity\n",
    "        valid = self.critic(img)\n",
    "        # Defines generator model\n",
    "        self.generator_model = Model(z_gen, valid)\n",
    "        self.generator_model.compile(loss=self.wasserstein_loss, optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def gradient_penalty_loss(self, y_true, y_pred, averaged_samples):\n",
    "        \"\"\"\n",
    "        Computes gradient penalty based on prediction and weighted real / fake samples\n",
    "        \"\"\"\n",
    "        gradients = K.gradients(y_pred, averaged_samples)[0]\n",
    "        # compute the euclidean norm by squaring ...\n",
    "        gradients_sqr = K.square(gradients)\n",
    "        #   ... summing over the rows ...\n",
    "        gradients_sqr_sum = K.sum(gradients_sqr,\n",
    "                                  axis=np.arange(1, len(gradients_sqr.shape)))\n",
    "        #   ... and sqrt\n",
    "        gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
    "        # compute lambda * (1 - ||grad||)^2 still for each single sample\n",
    "        gradient_penalty = K.square(1 - gradient_l2_norm)\n",
    "        # return the mean as loss over all the batch samples\n",
    "        return K.mean(gradient_penalty)\n",
    "\n",
    "\n",
    "    def wasserstein_loss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "\n",
    "    \n",
    "    def train(self, X_train, epochs, sample_interval=50):\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = -np.ones((self.batch_size, 1))\n",
    "        fake =  np.ones((self.batch_size, 1))\n",
    "        dummy = np.zeros((self.batch_size, 1)) # Dummy gt for gradient penalty\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for _ in range(self.n_critic):\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Select a random batch of images\n",
    "                idx = np.random.randint(0, X_train.shape[0], self.batch_size)\n",
    "                imgs = X_train[idx]\n",
    "                # Sample generator input\n",
    "                noise = np.random.normal(0, 1, (self.batch_size, self.latent_dim))\n",
    "                # Train the critic\n",
    "                d_loss = self.critic_model.train_on_batch([imgs, noise],\n",
    "                                                                [valid, fake, dummy])\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            g_loss = self.generator_model.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f] [G loss: %f]\" % (epoch, d_loss[0], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.save_imgs(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(GAN):\n",
    "    def __init__(self, img_rows, img_cols, channels, batch_size):\n",
    "        super().__init__(img_rows, img_cols, channels, batch_size)\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator(final_activation='sigmoid')\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        \n",
    "    def train(self, X_train, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        #X_train = train_data / 127.5 - 1.\n",
    "        #X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select random batch\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise and generate a batch of new images\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 31, 233, 64)       22848     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 31, 233, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 31, 233, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 16, 117, 64)       16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 16, 117, 64)       256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 16, 117, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 16, 117, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 8, 59, 64)         16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 8, 59, 64)         256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 8, 59, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 8, 59, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 30208)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 30209     \n",
      "=================================================================\n",
      "Total params: 86,465\n",
      "Trainable params: 86,209\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "Generator model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 512)               51712     \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 2, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_31 (Conv2DT (None, 6, 67, 64)         1048640   \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 6, 67, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 6, 67, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_32 (Conv2DT (None, 14, 136, 64)       65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 14, 136, 64)       256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 14, 136, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_33 (Conv2DT (None, 30, 274, 64)       65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 30, 274, 64)       256       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 30, 274, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_34 (Conv2DT (None, 61, 550, 64)       49216     \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 61, 550, 64)       256       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 61, 550, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_35 (Conv2DT (None, 64, 553, 1)        1025      \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 64, 553, 1)        4         \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 64, 553, 1)        0         \n",
      "=================================================================\n",
      "Total params: 1,282,821\n",
      "Trainable params: 1,282,307\n",
      "Non-trainable params: 514\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programs\\python\\lib\\site-packages\\keras\\engine\\training.py:479: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.962589, acc.: 53.12%] [G loss: 0.777109]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "1 [D loss: 0.499962, acc.: 75.00%] [G loss: 1.820102]\n",
      "2 [D loss: 0.172896, acc.: 100.00%] [G loss: 2.754769]\n",
      "3 [D loss: 0.313185, acc.: 90.62%] [G loss: 2.600304]\n",
      "4 [D loss: 0.268662, acc.: 87.50%] [G loss: 1.595285]\n",
      "5 [D loss: 0.113486, acc.: 100.00%] [G loss: 1.341021]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "6 [D loss: 0.105804, acc.: 96.88%] [G loss: 0.873343]\n",
      "7 [D loss: 0.082974, acc.: 100.00%] [G loss: 0.636848]\n",
      "8 [D loss: 0.056748, acc.: 100.00%] [G loss: 0.576613]\n",
      "9 [D loss: 0.085568, acc.: 100.00%] [G loss: 0.640225]\n",
      "10 [D loss: 0.089655, acc.: 100.00%] [G loss: 0.533587]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "11 [D loss: 0.090927, acc.: 100.00%] [G loss: 0.706277]\n",
      "12 [D loss: 0.064590, acc.: 100.00%] [G loss: 0.993256]\n",
      "13 [D loss: 0.116472, acc.: 96.88%] [G loss: 0.839382]\n",
      "14 [D loss: 0.098314, acc.: 96.88%] [G loss: 0.974491]\n",
      "15 [D loss: 0.066028, acc.: 100.00%] [G loss: 1.116627]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "16 [D loss: 0.083016, acc.: 100.00%] [G loss: 1.634968]\n",
      "17 [D loss: 0.040898, acc.: 100.00%] [G loss: 1.903162]\n",
      "18 [D loss: 0.143320, acc.: 96.88%] [G loss: 1.756015]\n",
      "19 [D loss: 0.070569, acc.: 100.00%] [G loss: 2.046825]\n",
      "20 [D loss: 0.061307, acc.: 100.00%] [G loss: 1.892189]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "21 [D loss: 0.106218, acc.: 96.88%] [G loss: 3.477117]\n",
      "22 [D loss: 0.077704, acc.: 100.00%] [G loss: 3.355756]\n",
      "23 [D loss: 0.095153, acc.: 96.88%] [G loss: 2.809547]\n",
      "24 [D loss: 0.111730, acc.: 100.00%] [G loss: 4.270309]\n",
      "25 [D loss: 0.069817, acc.: 100.00%] [G loss: 4.490882]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "26 [D loss: 0.079260, acc.: 100.00%] [G loss: 5.078431]\n",
      "27 [D loss: 0.042615, acc.: 100.00%] [G loss: 5.376301]\n",
      "28 [D loss: 0.041638, acc.: 100.00%] [G loss: 4.992523]\n",
      "29 [D loss: 0.027318, acc.: 100.00%] [G loss: 4.891228]\n",
      "30 [D loss: 0.019851, acc.: 100.00%] [G loss: 5.206190]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "31 [D loss: 0.026468, acc.: 100.00%] [G loss: 5.685176]\n",
      "32 [D loss: 0.024514, acc.: 100.00%] [G loss: 5.398431]\n",
      "33 [D loss: 0.020478, acc.: 100.00%] [G loss: 4.601647]\n",
      "34 [D loss: 0.022373, acc.: 100.00%] [G loss: 5.577459]\n",
      "35 [D loss: 0.019015, acc.: 100.00%] [G loss: 5.785930]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "36 [D loss: 0.022104, acc.: 100.00%] [G loss: 5.626658]\n",
      "37 [D loss: 0.028067, acc.: 100.00%] [G loss: 6.003257]\n",
      "38 [D loss: 0.016820, acc.: 100.00%] [G loss: 6.336582]\n",
      "39 [D loss: 0.014524, acc.: 100.00%] [G loss: 6.011022]\n",
      "40 [D loss: 0.013545, acc.: 100.00%] [G loss: 5.930887]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "41 [D loss: 0.013770, acc.: 100.00%] [G loss: 6.256334]\n",
      "42 [D loss: 0.014716, acc.: 100.00%] [G loss: 6.144954]\n",
      "43 [D loss: 0.009452, acc.: 100.00%] [G loss: 6.810809]\n",
      "44 [D loss: 0.011483, acc.: 100.00%] [G loss: 6.655351]\n",
      "45 [D loss: 0.009790, acc.: 100.00%] [G loss: 6.613349]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "46 [D loss: 0.008153, acc.: 100.00%] [G loss: 6.625332]\n",
      "47 [D loss: 0.008067, acc.: 100.00%] [G loss: 6.296097]\n",
      "48 [D loss: 0.008001, acc.: 100.00%] [G loss: 6.694647]\n",
      "49 [D loss: 0.006317, acc.: 100.00%] [G loss: 6.142159]\n",
      "50 [D loss: 0.009999, acc.: 100.00%] [G loss: 6.609178]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "51 [D loss: 0.011494, acc.: 100.00%] [G loss: 6.447494]\n",
      "52 [D loss: 0.005621, acc.: 100.00%] [G loss: 6.807878]\n",
      "53 [D loss: 0.004336, acc.: 100.00%] [G loss: 6.887423]\n",
      "54 [D loss: 0.008989, acc.: 100.00%] [G loss: 6.862198]\n",
      "55 [D loss: 0.007409, acc.: 100.00%] [G loss: 6.752713]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "56 [D loss: 0.007306, acc.: 100.00%] [G loss: 6.872577]\n",
      "57 [D loss: 0.003099, acc.: 100.00%] [G loss: 6.924221]\n",
      "58 [D loss: 0.005096, acc.: 100.00%] [G loss: 6.855314]\n",
      "59 [D loss: 0.004486, acc.: 100.00%] [G loss: 6.652498]\n",
      "60 [D loss: 0.004441, acc.: 100.00%] [G loss: 6.778587]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "61 [D loss: 0.007112, acc.: 100.00%] [G loss: 6.772976]\n",
      "62 [D loss: 0.003935, acc.: 100.00%] [G loss: 6.943360]\n",
      "63 [D loss: 0.006019, acc.: 100.00%] [G loss: 6.857598]\n",
      "64 [D loss: 0.004853, acc.: 100.00%] [G loss: 7.212750]\n",
      "65 [D loss: 0.004167, acc.: 100.00%] [G loss: 7.134439]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "66 [D loss: 0.002217, acc.: 100.00%] [G loss: 7.096709]\n",
      "67 [D loss: 0.007211, acc.: 100.00%] [G loss: 6.868231]\n",
      "68 [D loss: 0.003929, acc.: 100.00%] [G loss: 7.536461]\n",
      "69 [D loss: 0.002578, acc.: 100.00%] [G loss: 7.189267]\n",
      "70 [D loss: 0.003363, acc.: 100.00%] [G loss: 7.490481]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "71 [D loss: 0.001996, acc.: 100.00%] [G loss: 6.814191]\n",
      "72 [D loss: 0.004274, acc.: 100.00%] [G loss: 6.987289]\n",
      "73 [D loss: 0.002015, acc.: 100.00%] [G loss: 6.877493]\n",
      "74 [D loss: 0.002995, acc.: 100.00%] [G loss: 7.285319]\n",
      "75 [D loss: 0.002664, acc.: 100.00%] [G loss: 6.791113]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "76 [D loss: 0.002640, acc.: 100.00%] [G loss: 7.094056]\n",
      "77 [D loss: 0.003489, acc.: 100.00%] [G loss: 6.773305]\n",
      "78 [D loss: 0.003656, acc.: 100.00%] [G loss: 6.809911]\n",
      "79 [D loss: 0.002427, acc.: 100.00%] [G loss: 7.262659]\n",
      "80 [D loss: 0.002614, acc.: 100.00%] [G loss: 7.066767]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "81 [D loss: 0.002221, acc.: 100.00%] [G loss: 7.762242]\n",
      "82 [D loss: 0.001911, acc.: 100.00%] [G loss: 6.988841]\n",
      "83 [D loss: 0.002950, acc.: 100.00%] [G loss: 6.599401]\n",
      "84 [D loss: 0.002061, acc.: 100.00%] [G loss: 6.947678]\n",
      "85 [D loss: 0.001762, acc.: 100.00%] [G loss: 6.861664]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "86 [D loss: 0.001973, acc.: 100.00%] [G loss: 6.989355]\n",
      "87 [D loss: 0.001925, acc.: 100.00%] [G loss: 6.908216]\n",
      "88 [D loss: 0.001603, acc.: 100.00%] [G loss: 7.354068]\n",
      "89 [D loss: 0.001085, acc.: 100.00%] [G loss: 7.059932]\n",
      "90 [D loss: 0.001116, acc.: 100.00%] [G loss: 6.848126]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "91 [D loss: 0.001303, acc.: 100.00%] [G loss: 6.536089]\n",
      "92 [D loss: 0.001230, acc.: 100.00%] [G loss: 6.700667]\n",
      "93 [D loss: 0.002060, acc.: 100.00%] [G loss: 7.322002]\n",
      "94 [D loss: 0.001733, acc.: 100.00%] [G loss: 6.993877]\n",
      "95 [D loss: 0.001731, acc.: 100.00%] [G loss: 6.940415]\n",
      "Generated shape (1, 64, 553, 1)\n",
      "96 [D loss: 0.001840, acc.: 100.00%] [G loss: 7.088105]\n",
      "97 [D loss: 0.002491, acc.: 100.00%] [G loss: 6.723559]\n",
      "98 [D loss: 0.001407, acc.: 100.00%] [G loss: 6.494537]\n",
      "99 [D loss: 0.001022, acc.: 100.00%] [G loss: 6.673509]\n",
      "100 [D loss: 0.001096, acc.: 100.00%] [G loss: 7.319561]\n",
      "Generated shape (1, 64, 553, 1)\n"
     ]
    }
   ],
   "source": [
    "(n_samples, pitch_level, time_span) = samples.shape\n",
    "train_data = samples.reshape(n_samples, pitch_level, time_span, 1)\n",
    "\n",
    "#dcgan = DCGAN(pitch_level,time_span,1)\n",
    "#dcgan.train(train_data, epochs=1000, batch_size=64, save_interval=50)\n",
    "\n",
    "wgan = WGANGP(pitch_level, time_span, 1, batch_size=64)\n",
    "wgan.train(train_data, epochs=30000, sample_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
